{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 1500, num = 3)]\n",
    "max_features = [.2, 5]#, 'log2']  # Number of features to consider at every split\n",
    "max_depth = [2,4]#[int(x) for x in np.linspace(2, 5, num = 3)]   # Maximum number of levels in tree\n",
    "#max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]  # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 10, 15]    # Minimum number of samples required at each leaf node\n",
    "bootstrap = [True]                # Method of selecting samples for training each tree\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_leaf_nodes': [None] + list(np.linspace(15, 60, 4).astype(int)),\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1)\n",
    "rf_random = RandomizedSearchCV(\n",
    "                estimator = rf,\n",
    "                param_distributions = random_grid,\n",
    "                n_iter = 150, cv = 3,\n",
    "                verbose=1, random_state=22,\n",
    "                scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_random = make_pipeline(col_trans, rf_random)\n",
    "pipe_random.fit(train_x, train_y)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_params_lst = []\n",
    "pipe_best_model_lst = []\n",
    "top_five = ['NAmes', 'CollgCr']#, 'OldTown', 'Edwards', 'Somerst']\n",
    "top_five_dicts = []\n",
    "for name in top_five:\n",
    "    print(name)\n",
    "    name_ = train_xy.loc[train_xy['Neighborhood'] == name].reset_index(drop=True)\n",
    "    t_x = name_.iloc[:,1:]\n",
    "    t_y = name_.iloc[:,-1:]\n",
    "    col_trans = make_column_transformer(\n",
    "                        (OneHotEncoder(),t_x.columns.tolist()),\n",
    "                        remainder = \"passthrough\"\n",
    "                        )\n",
    "    pipe_random = make_pipeline(col_trans, rf_random)\n",
    "    pipe_random.fit(t_x, t_y)\n",
    "    rf_random.best_params_\n",
    "    best_params_lst.append(rf_random.best_params_)\n",
    "    pipe_best_model_lst.append(pipe_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_best_model_lst[0].fit(t_x,t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To look at nodes and depths of trees use on average\n",
    "n_nodes = []\n",
    "max_depths = []\n",
    "est_ = []\n",
    "\n",
    "\n",
    "\n",
    "best_model = rf_random.best_estimator_\n",
    "pipe_best_model = make_pipeline(col_trans, best_model)\n",
    "pipe_best_model.fit(train_x, train_y)\n",
    "#y_pred_best_model = pipe_best_model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to reshape the data to fit\n",
    "np.array(t_y)[:, None].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_best_model.score(t_x,(np.array(t_y)[:, None].reshape(-1,1)))#train_x, train_y)\n",
    "#pipe_best_model.oob_score(train_x, train_y)\n",
    "#ind_tree.tree_.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_tree in best_model.estimators_:\n",
    "       n_nodes.append(ind_tree.tree_.node_count)\n",
    "       max_depths.append(ind_tree.tree_.max_depth)\n",
    "       est_.append(ind_tree.score)\n",
    "       \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')   \n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_ = encode_and_bind(t_x, t_x.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(est_limited, out_file='tree.dot', feature_names= X_train_encoded_,#X_train_encoded.columns,\n",
    "                class_names = t_y, rounded = True, proportion = False,\n",
    "                precision = 2, filled = True)\n",
    "\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', 'Gdpi=600'])\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(test_x.columns):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = pipe_best_model.predict(train_x)\n",
    "train_rf_probs = pipe_best_model.predict_proba(train_x)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_rf_predictions))\n",
    "for i, v in enumerate(train_rf_predictions):\n",
    "    print(v, train_y[i], train_rf_probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame([train_rf_predictions, train_y[::1], train_rf_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions\n",
    "train_rf_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns = ['Predicted', 'Actual', 'Prob_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_pred, probs,train_predictions, train_probs):\n",
    "    baseline = {}\n",
    "    baseline['recall']=recall_score(y_test,\n",
    "                    [1 for _ in range(len(y_test))])\n",
    "    baseline['precision'] = precision_score(y_test,\n",
    "                    [1 for _ in range(len(y_test))])\n",
    "    baseline['roc'] = 0.5\n",
    "    results = {}\n",
    "    results['recall'] = recall_score(y_test, y_pred)\n",
    "    results['precision'] = precision_score(y_test, y_pred)\n",
    "    results['roc'] = roc_auc_score(y_test, probs)\n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(y_train,       train_predictions)\n",
    "    train_results['precision'] = precision_score(y_train, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(y_train, train_probs)\n",
    "    for metric in ['recall', 'precision', 'roc']:  \n",
    "          print(f'{metric.capitalize()} \\\n",
    "                 Baseline: {round(baseline[metric], 2)} \\\n",
    "                 Test: {round(results[metric], 2)} \\\n",
    "                 Train: {round(train_results[metric], 2)}')\n",
    "     # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate');\n",
    "    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n",
    "    plt.show();\n",
    "#evaluate_model(y_pred_best_model,rf_probs,train_rf_predictions,train_rf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
